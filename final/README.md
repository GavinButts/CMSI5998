# CMSI 5998 Final Project

In this folder, we provide the pipeline for data filtering, data accumulation, data preprocessing, model training, and model evaluation. To run the entire data pipeline, find section **Run Project**. To run individual steps of the pipeline, please find **File Descriptions**.
\
&nbsp;
\
&nbsp;

## File Descriptions  

#### BuildDatabase.py

> This file establishes a connection to MongoDB database, scrapes NewsAPI for key-words listed in ***cs_terms.txt***, and puts the data into database.

***TO RUN***
```
export NEWSAPI_KEY=0 #set NewsAPI key here
export MONGODB_URI=0 #set MongoDB URI here

python BuildDatabase.py
```

\
&nbsp;


#### cs_terms.py

> This file provides a large list of terms that relate to recent fields or advancements in computer science or mathematics. The list was generated by GPT-4o.

\
&nbsp;



#### NewsLlama.py

> This file connects to HuggingFace API and loads TinyLlama, a pre-trained parameter reduced variant of Meta's Llama 2. Then, after establishing a connection to MongoDB, pulls the data from the database, preprocesses it, and fully fine-tunes TinyLlama. I terms this fine-tuned model NewsLlama.

***TO RUN***
```
export MONGODB_URI=0 #set MongoDB URI here
export HF_API_KEY=0 #set Hugging Face API key here

python NewsLlama.py
```

\
&nbsp;




